# Reactor sous le capot 

## Les diff√©rents mod√®les d'ex√©cution:  

Pour illustrer les diff√©rents mod√®les d'ex√©cution, on va utiliser l'image du restaurant ou : 
* la salle : l'application
* la cuisine : la base de donn√©es
* un serveur : un thread 
* les clients / une table : une requ√™te 

### Servlet 

![Servlet](./resources/servlet.png "Servlet")

Dans le monde servlet nous aurons un server par table. 
Le server va 
* accueillir le client
* le placer
* attendre sa commande 
* passer sa commande en cuisine 
* attendre ses plats 
* encaisser le paiement 

Une fois tout √ßa, il pourra passer au client suivant. Dans cette hypoth√®se, le serveur passe beaucoup de temps √† attendre. 

Sous charge, quand tous les serveurs sont occup√©s, les clients doivent attendre : 

![Servlet](./resources/servlet_charge.png "Servlet sous charge")

### Mode non bloquant

Dans le mode non bloquant, on ne bloque pas le thread lors des IOs. Le thread est lib√©r√© pour effectuer d'autres taches. 

En mode restaurant, c'est ce qu'on connait, des servers qui passent de client en client. 

![Servlet](./resources/nonbloquant.png "Non bloquant")

Sous charge, on peut imaginer servir un nombre de tables vraiment important, ici c'est la cuisine qui va gal√©rer car si elle est trop lente, les commandes vont s'accumuler. 

![Servlet](./resources/nonbloquantcharge.png "Non bloquant sous charge")

### Reactive stream 

Dans la spec reactive stream, il y a une gestion de "back pressure" autrement appel√© "flow control". 

Dans le cas du restaurant, c'est la cuisine qui va piloter la charge en fonction de sa capacit√©. 

Sous charge, on √™tre dans le m√™me cas que servlet, les clients vont faire la queue. Par contre on utilise un nombre de serveur (thread) limit√©.


## Dans spring reactor 

Spring reactor propose des `Flux` et des `Mono` : 
* `Mono` un r√©sultat (ou pas de r√©sultat) qui n'est pas encore l√† 
* `Flux` une collection d'√©l√©ments qui vont arriver au fur et √† mesure

Pour illustrer les m√©canismes de back pressure, on va s'int√©resser aux `Flux`. 

Un `Flux<T>` va √©mettre des √©l√©ments de type `T`, il existe tout un tas d'op√©rateurs qui vont nous permettre de filtrer (`filter`), transformer (`map`, `flatMap`, `concatMap` ...), grouper (`buffer`, `bufferTimeout`, `scan` `reduce` ...), ajouter du d√©lai (`delayElements`) etc, un peu comme les streams du JDK.    

La diff√©rence entre le JDK et reactor, c'est que dans les reactor les √©l√©ments arrivent au fur et √† mesure, on est dans un push plut√¥t que pull. 

Une autre diff√©rence importante, c'est qu'un flux n'est qu'un plan d'ex√©cution. Tant qu'on a pas fait `subscribe` rien ne se passe.
C'est la diff√©rence majeure entre `Mono` et `CompletionStage`, un `CompletionStage` est d√©j√† ex√©cut√© et on attend le r√©sultat, √ßa n'est pas le cas pour un `Mono` qui est "lazy".  

Nous allons impl√©menter un `Flux` custom : un compteur. Pour faire on va utiliser `create` qui va nous donner un `sink` qui permettra de piloter nos actions

```java
Flux<Long> counterFlux = Flux.create(sink -> {
    AtomicLong counter = new AtomicLong(0);
    // onRequest : le consommateur du stream nous demande n √©l√©ments 
    sink.onRequest(req -> {
        System.out.println("Request " + req);
        // On produit les n √©l√©ments en incr√©mentant notre compteur : 
        for (int i = 0; i < req; i++) {
            // On utiliser sink.next pour publier les √©l√©ments downstream 
            sink.next(counter.incrementAndGet());
        }
    });
    // Do on cancel
    sink.onCancel(() -> {
        System.out.println("Cancel");
    });
    // Do on terminate
    sink.onDispose(() -> {
        System.out.println("Terminate");
    });
});
```

Maintenant on va pouvoir constater l'impact des op√©rateurs sur la gestion de la backpressure √† travers la demande. 

### Un simple abonnement 

```java
counterFlux
        .subscribe(
            n -> {
                System.out.println("Next valeur = " + n);
            },
            e -> {
                e.printStackTrace();
            },
            () -> {
                System.out.println("Complete");
                cdl.countDown();
            }
        );
```

Ici on va s'abonner au flux et donc l'executer. On aura les logs suivant : 

```
Request 9223372036854775807
Next valeur = 1
Next valeur = 2
Next valeur = 3
Next valeur = 4
...
```

Ici aucune raison de r√©guler la vitesse du flux, la demande est `Long.MAX_VALUE` √† savoir 9223372036854775807. 

### Take 

L'op√©rateur take permet de ne prendre que les n premiers √©l√©ments et de stopper le stream. 

```java
counterFlux
        .take(5)
        .subscribe(
            n -> {
                System.out.println("Next valeur = " + n);
            },
            e -> {
                e.printStackTrace();
            },
            () -> {
                System.out.println("Complete");
                cdl.countDown();
            }
        );
```

On aura les logs suivants 
```
Request 5
Next valeur = 1
Next valeur = 2
Next valeur = 3
Next valeur = 4
Next valeur = 5
Complete
Cancel
Terminate
```

Ici on voit que la demande a √©t√© adapt√© par l'op√©rateur take. 
La demande remonte du consommateur vers le producteur, `subscribe` demande `Long.MAX_VALUE` mais la demande est overrid√© par `take` qui lui ne demande que le nombre n√©cessaire, ici 5.

`take` demande 5, la source publie 5 √©l√©ments, puis le stream est termin√©.

### Delay 

L'op√©rateur delay va ajouter un d√©lai entre chaque √©l√©ment, voyant comme se comporte cet op√©rateur. 

```java
counterFlux
        .delayElements(Duration.ofSeconds(1))
        .subscribe(
            n -> {
                System.out.println("Next valeur = " + n);
            },
            e -> {
                e.printStackTrace();
            },
            () -> {
                System.out.println("Complete");
                cdl.countDown();
            }
        );
```

```
Request 1
Next valeur = 1
Request 1
Next valeur = 2
Request 1
Next valeur = 3
Request 1
Next valeur = 4
Request 1
Next valeur = 5
Request 1
Next valeur = 6
Request 1
Next valeur = 7
...
```

Ici on voit qu'une demande de 1 est formul√©e pour chaque √©l√©ment. 
Comme un d√©lai est ins√©r√© entre chaque √©l√©ment, l'op√©rateur d√©lai ne demande qu'1 seul √©l√©ment. 
Ceci permet de contr√¥ler la conso m√©moire en ne demandant que ce qui est n√©cessaire.  

Si on combine avec buffer (op√©rateur qui permet de faire des paquet de n √©l√©ment), on peut avoir des comportements diff√©rents suivant l'ordre dans lesquels les op√©rateurs sont plac√©s : 

```java
counterFlux
    .buffer(4)
    .delayElements(Duration.ofSeconds(1))
    ...
```

```
Request 4
Next valeur = [1, 2, 3, 4]
Request 4
Next valeur = [5, 6, 7, 8]
Request 4
Next valeur = [9, 10, 11, 12]
Request 4
Next valeur = [13, 14, 15, 16]
...
```
Ici delayElements demande 1 √©l√©ment mais la demande est surcharg√©e par buffer qui en demande 4. 

√† l'inverse 

```java
counterFlux
    .buffer(4)
    .delayElements(Duration.ofSeconds(1))
    ...
```
buffer demande 4 √©l√©ment mais la demande est surcharg√©e par delayElements qui en demande 1. On peut observer √ßa dans les logs : 

```
Request 1
Request 1
Request 1
Request 1
Next valeur = [1, 2, 3, 4]
Request 1
Request 1
Request 1
Request 1
Next valeur = [5, 6, 7, 8]
...
```

### flatMap

L'op√©rateur `flatMap` permet de faire de la composition. Comme `map` il permet d'appliquer une fonction sur chaque √©l√©ment √† la diff√©rence que le r√©sultat de la fonction sera lui m√™me un stream. 

Pour illustrer √ßa, on peut imagine un Flux d'identifiants et pour chaque id on va appeler une API (c'est IO et donc un Flux ou Mono). 

On pourrait avoir quelque chose comme : 

```java
Flux<ID> ids = services.listIds();
Flux<Personne> personnes = ids
        .flatMap(id -> {
            Mono<Personne> personne = getPersonneById(id);
            return personne;
        });
```

Voyons maintenant comme se comporte `flatMap` sur la demande. On se concentre uniquement sur la gestion de la demande donc pas besoin de faire un appel compliqu√©, on juste retourner l'√©l√©ment courant. 

```java
counterFlux
    .flatMap(elt -> 
            // On ajoute un d√©lai de 1 seconde pour symboliser un appel d'api 
            Mono.just(elt).delayElement(Duration.ofSeconds(1))
    )
```

R√©sultat : 

```
Request 256
Next valeur = 2
Request 1
Next valeur = 10
Request 1
Next valeur = 18
Request 1
Next valeur = 26
Request 1
Next valeur = 34
Request 1
Next valeur = 42
Request 1
Next valeur = 50
Request 1
Next valeur = 58
Request 1
Next valeur = 66
```

üò± mais que se passe t-il ?!? 
1. On voit que la requ√™te est de 256 !!! 
2. On voit que les √©l√©ments arrive dans le d√©sordre 

En fait par d√©faut flatMap cherche √† parall√©liser ses traitements et la valeur de la demande par d√©faut c'est 256. 
Si on appelait une API, on ferait 256 appels concurrent, et les r√©sultats seraient entrem√™l√©s !

![FlatMap](./resources/flatmap.png "FlatMap")

Ce n'est pas forc√©ment le comportement souhait√© par la plupart des utilisateurs ! Donc attention ! 

Pour ne faire qu'un traitement √† la fois il existe `concatMap` :  
```java
counterFlux
    .concatMap(elt -> 
            // On ajoute un d√©lai de 1 seconde pour symboliser un appel d'api 
            Mono.just(elt).delayElement(Duration.ofSeconds(1))
    )
```

On a alors : 

```
Request 1
Next valeur = 1
Request 1
Next valeur = 2
Request 1
Next valeur = 3
Request 1
Next valeur = 4
Request 1
Next valeur = 5
```